# README for ChromaDB and RAG Pipeline Application (Assignment 2)

## Table of Contents
1. [Introduction](#introduction)  
2. [Features](#features)  
3. [Setup and Installation](#setup-and-installation)  
4. [Usage](#usage)  
5. [File Descriptions](#file-descriptions)  
6. [Technical Details](#technical-details)  
7. [Examples](#examples)  
8. [License](#license)  

---

## Introduction
This project is an enhanced version of the chatbot application from **Assignment 1**, implementing a Retrieval-Augmented Generation (RAG) pipeline using **ChromaDB** and **Ollama llama3.2**. In this version, users can upload documents, and the chatbot will provide context-aware answers based on the content of those uploaded files.

The web interface is built using **Streamlit**, allowing users to interact with the chatbot by inputting prompts, uploading files, and receiving intelligent responses based on the knowledge stored in **ChromaDB**.

---

## Features
- **Document Upload and Processing**: Users can upload one or more `.txt` files, which are then processed and stored in the vector database.
- **Contextual Querying**: The chatbot retrieves relevant information from the uploaded documents to answer user queries within the context of those files.
- **Vector Indexing and Efficient Querying**: Leverages **ChromaDB** for scalable, high-performance vector data retrieval.
- **RAG Pipeline**: Combines contextual knowledge retrieval with language modeling using **Ollama llama3.2**.
- **User-Friendly Interface**: Includes a web interface built with **Streamlit** for easy interaction.

---

## Setup and Installation

### Prerequisites
Make sure you have the following installed:
- Python 3.9 or later  
- pip  
- A running instance of the **Ollama server** (adjustable URL)

### Steps
1. Clone the repository:  
   ```bash
   git clone <repository-link>
   cd <repository-name>
   ```

2. Install the required Python libraries:  
   ```bash
   pip install -r requirements.txt
   ```

3. Run the **Streamlit** application:  
   ```bash
   streamlit run app.py
   ```

4. Open the application in your browser (Streamlit will provide a local URL).

---

## Usage
1. **Enter your query** in the provided text area.  
2. **Upload `.txt` files** using the upload button.  
3. The application will process the uploaded documents and store them in **ChromaDB**.  
4. **Ask questions** about the uploaded documents, and the chatbot will provide context-based responses.  
5. **Press the Generate button** to receive the response.  

---

## File Descriptions
1. **app.py** ([source](src/app.py))  
   - Implements the backend logic for the RAG pipeline, file upload functionality, and Streamlit interface.  
   - Uses **ChromaDB** for vector indexing and **Ollama llama3.2** for response generation.  

2. **page.html** ([source](src/page.html))  
   - Contains the HTML for a supplementary web interface describing the file upload feature and query process.  

3. **style.css** ([source](src/style.css))  
   - Styles the content of `page.html` and the **Streamlit** interface.  

4. **requirements.txt** ([source](requirements.txt))  
   - Lists the necessary Python packages for the project.  

---

## Technical Details

### Document Upload and Processing
The project includes a document upload feature that accepts `.txt` files. Once uploaded, these files are processed, and their contents are embedded and stored in **ChromaDB**.

### ChromaDB Initialization
The project uses **chromadb.PersistentClient** for database interactions, initialized with:
- A specific database path  
- A custom embedding function based on the **langchain_ollama** library  

### RAG Pipeline Workflow
1. **Knowledge Retrieval**: Queries **ChromaDB** for documents matching the user prompt.  
2. **Prompt Augmentation**: Enhances the user input with relevant content from the uploaded documents.  
3. **LLM Response Generation**: Processes the augmented prompt via **Ollama llama3.2** to generate a contextual response.  

---

## Examples

Here are some example queries and the responses generated by the chatbot using uploaded documents:

### Example 1
**Uploaded Document**:  
`file1.txt` contains the following text:  
> "The capital of Japan is Tokyo. It is one of the most populous cities in the world."

**Input Query**: What is the capital of Japan?  
**AI Response**: Based on the uploaded document, the capital of Japan is Tokyo.

### Example 2
**Uploaded Document**:  
`photosynthesis.txt` contains the following text:  
> "Photosynthesis is the process by which plants convert light energy into chemical energy."

**Input Query**: Explain photosynthesis.  
**AI Response**: Based on the uploaded document, photosynthesis is the process by which plants convert light energy into chemical energy.

---

## License
This project is released under the **MIT License**. Feel free to use, modify, and distribute the code, provided proper attribution is given.
